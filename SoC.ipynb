{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Di_czVqTcsST",
    "outputId": "88cb5d54-1fbf-4286-b17a-3f49fdda0265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers peft accelerate bitsandbytes datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_om2bmcc6Sj",
    "outputId": "84d14065-19c0-44a7-b79d-01a68e78b636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug  2 13:04:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "2850a2c230d647b0bde04d8324952684",
      "f4779dc42b8c407d80b583b05dc79fc4",
      "e4f6098aca234db38c1e63a3c5991c4b",
      "178c4602cabd4161887ab792a37ddffb",
      "b4e185ce7b604440bbd3bade3a8235dc",
      "24c37f74c8c046098fff3251e6661b12",
      "311d6cd49c2a40beb7265162df7099e6",
      "48c1e773d80442eb9bf120692d51b27f",
      "2b16c2d2f53a41c3939c0734b2b852d8",
      "d65f74acc08f46fd97d62c6cbcd65467",
      "ba6199707d714ebd99b8ac721163c073",
      "4e3399edb0624a64b26c130f16a52230",
      "c43db5278535464f866751b530e3b0d6",
      "14c204d1d91f445db660d259ea8a8d0a",
      "d9f0372486254db39dee2ed1f595a8cb",
      "5e057e45fdd84d4082c4feaeea9685e1",
      "61adc4383df54cb8a07b8bf09e6357d9",
      "9e79d8cb2839449a9c401d1fcfdb2b2d",
      "3aa2343a6a6d4190b27464eef3ec8a54",
      "8b5d819df8484143a23b29c0301c9e74"
     ]
    },
    "id": "odnnj83de7fu",
    "outputId": "d734b87d-5213-49e0-ee1f-ed394547cf13"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2850a2c230d647b0bde04d8324952684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "d3287f5ec42145c196f556ee2845ad9b",
      "c99d4e0c1e0b4d8b9e5c49c625c1c856",
      "489d38e952c14925a7b901e108f93ab0",
      "d4f5b86dfa2348c3ab0f056654593383",
      "97d2938107ff40adbd1905ba862f5d39",
      "1df2ecc76a024da9a701cc1bd8875f6b",
      "004660f6768043eaabe514d3f7e1dc2e",
      "d858404ab79b4a4b91f4c68db07bbf6f",
      "76f761dc00cc4733918d7433f1acfc8c",
      "68e8bbc75ef147a2aafdd96860794b7e",
      "16e3ad53966e48b980f612859bb392d2",
      "21aaad0453ef492c8e9afcfcf583cbfd",
      "9046320c3c734bc2b314949cbcf6c437",
      "78b116f9975f4d15aeb076ed465aa623",
      "16c609185c3f4f5ab265edc6413afe99",
      "6e165868f8904786932633dc9ab601eb",
      "7544b5fa48f0469bbcf33eadde5fbea7",
      "743191e0eeba43429ec7551f84cac129",
      "f476b88653ec4804b5d134e6ea8a1d6f",
      "33e91d09953a419d830fa70e094cd694",
      "977e3a9068ba4cdcabdeccd5f5f1f6e6",
      "f6ccc2c076f84497a6baa65726cab546",
      "8c91fce8b8754c66ac1fff9814605a67",
      "414b60782fa0416fa8db78a94a733379",
      "da377aa34230474a88c33806ed4d4ded",
      "33c0e1ec3591444d8a4affeefe9d97e5",
      "f700e2027bb04bf9ab9501336f6f4e62",
      "efd07d5f8dd749db87e1cef51e6ff4ad",
      "fcb417b172514605af3b0822fd0d944a",
      "35bd7df548974950bb57f543acc1cc02",
      "aef0037dedfa42e69762fab6e3c5b262",
      "054817d3e69f47268c3c28c80627efb6",
      "72e191c6b01545f4828acd32e86a383e",
      "4fcae5bc2b284d8682a6fe6bf76fe6aa",
      "8a9849e52b26407e80426eea4a3738db",
      "3fecc5eeb9de4b728cc26ede703209f2",
      "21b89beb4c394a38bce5342735be5d03",
      "1f28f0c4f0d140ba86b67793eaf1ba15",
      "5d900fa902f9400daf4b6a906fd6ec08",
      "3e81a4c791ce48ff8786516eb390b1a0",
      "7ffbc52b549a4c06af09bd9195b4452a",
      "47950c8fe5464eeca64e84b7227c6551",
      "1c3df730159b4659a012142417fc2efd",
      "88959e68acc4462292a982be8fdb1e5b"
     ]
    },
    "id": "1c95gOzxdTUT",
    "outputId": "fb996e8a-0eef-49bd-d52c-b93c0361a75f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3287f5ec42145c196f556ee2845ad9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/522 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aaad0453ef492c8e9afcfcf583cbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-ab79bf9300210e98.parquet:   0%|          | 0.00/10.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c91fce8b8754c66ac1fff9814605a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcae5bc2b284d8682a6fe6bf76fe6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_ds = load_dataset(\"FinGPT/fingpt-fiqa_qa\")\n",
    "\n",
    "def format_gemma_instruction(example):\n",
    "    user_prompt = f\"{example['instruction'].strip()}\\n\\n{example['input'].strip()}\"\n",
    "    model_response = example['output'].strip()\n",
    "    formatted = f\"<start_of_turn>user\\n{user_prompt}<end_of_turn>\\n<start_of_turn>model\\n{model_response}<end_of_turn>\"\n",
    "    return {\"text\": formatted}\n",
    "\n",
    "formatted_ds = raw_ds[\"train\"].map(format_gemma_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "f5946b1263d54e3b9f1d44bcf29be7c8",
      "57d697bcbdc642eebad48e1c1aa7264c",
      "4ce5becf1aa341f3affd1ecfc13f3077",
      "56eb4a5e92164e11818841dffd7ac1c5",
      "3730a32e5fe84216a476e9f0ea93c1d0",
      "27328a8198c848d6bf666cc139d2b476",
      "6b8177065fcb497c8ef5cb3176f18670",
      "2d820af87dae4644a658f4514d9073e3",
      "e8bf17928ccb49b0b22b1a4926562db8",
      "9b9e17add4bd4708b0e2dcd0673e9d0c",
      "1ae649dd6c254283b4f9e7b46fa08892",
      "cb3d2b4404554ef38cc056280bc524ac",
      "e72868c8904646c4b787f8a78183b33c",
      "e59c6c1d68a147abb08c508d85c95660",
      "72942e9ae97745699a4457da6841ef7a",
      "eb7b892edf274db890d43945b2b5b48c",
      "9ab8a9ee90fc4d0c82d2ae31aee20087",
      "138f077b89bb4826b1c47e0ce57b0f66",
      "ddfd3a7766bd46bd9f6282014a3b1f48",
      "0140b8b83a3c459b895f98bcf8d05447",
      "49f6c4eb36ca44dda165e7c080158718",
      "f3eb22cc8ffb4bcb9d336e8600215f5d",
      "2c5a8d04c03a4218b079ca867ea94ac6",
      "4de61c4c9991498faa303ed0f14c2ebb",
      "c1443ef35bd644be97635da56e419ea2",
      "3cec6559df5c440fa91495db4f20d045",
      "b9f1ad0ad4be471ba470290ff466c54d",
      "322715af2c5242998eaaf1a649a3dc91",
      "485d5b53c0aa42af8481fabdfbdab6e2",
      "d8ba0bcab05d458a9cf4374bdaf0a50f",
      "96690a6b27964984bdfdad4c02438eef",
      "1536c16e36eb4ee38b39914816e0a660",
      "7e564702bfd345cca63ff4ed33f5bc4a",
      "e71b051ae5ec4f1ab2eff371d74915a5",
      "cd13d5e7d66246ff874709ecb57c8419",
      "c94de26944af4e2bbdf732493ed9b641",
      "aaf4a0ef1091480e8f4fedc2f3f5b090",
      "5c8ae409e2b7486b88b4dfdec2aedb33",
      "a918c0ae530c463d87839ca9024742fd",
      "c9f6d476f94a474a89fb8f605f56139e",
      "debca3dfd18c4d718675bf7b19217ad9",
      "a04cc784c5dd405887127e92b98c03d9",
      "f1dc6fe1d96d45759b3b24e426254b46",
      "a464bb2ac8d44654aa2fade0eda886d5",
      "80a53f888b874ad886632b1f19e27e54",
      "1cc052c042d14a129bfa0758485bdf6a",
      "464575d0d406493d87ff760d64e27086",
      "f53467afadbf4687b062dc943ef6d455",
      "e015ad9f85e9477a84ff273f2d85e4ee",
      "49ce00cece704882b3a0479d61c92389",
      "91f805a99c3b4c2497af69a6ac4c98f1",
      "274813c8a7f44e68b8b7b4b92ed6628c",
      "f57a5628cd1b498d8fb91b3776ae45f4",
      "b4ef42fd01cc407da0a0f0aa65b5b47f",
      "d8115ff0302343a39e08b6c9e09dd1e5"
     ]
    },
    "id": "ANKFxm4EgLJu",
    "outputId": "8f4d0be3-268d-406e-8f4b-2dc47905e173"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5946b1263d54e3b9f1d44bcf29be7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3d2b4404554ef38cc056280bc524ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5a8d04c03a4218b079ca867ea94ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71b051ae5ec4f1ab2eff371d74915a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a53f888b874ad886632b1f19e27e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\", token=True)\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_ds = formatted_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "referenced_widgets": [
      "ae00d74c8e7e4df4bf78a306a337ae01",
      "2377b7c3d0cf4e3b95451655ff8402d0",
      "5822fb45a5c44aed818b37394564aefc",
      "0f48ebc5f0054a608842c8194c3bf77f",
      "13d36d40a7ed46b08697a1e99992a8e7",
      "ecf95b9b8ba5458aa7707ac522ad0541",
      "43d26e707d314aa6a44c386b4887f013",
      "70d8bd2135d541f0bcb7a37101b758a4",
      "7f3ff54515c34656b95a4b1b40ee5d0f",
      "9c032efa20514c0f990711db571fccf3",
      "91b9de4fc3a24be59522190951db5c2b",
      "6b66a539cf6a44e9b91b4c83727f8b7e",
      "3401225b1ef8493389f2004720807fa8",
      "f269c4a18aba4e81adc26cf7d5d39698",
      "30af26e2de764a86a6738a56ed79f5e2",
      "af51a0eb3e574878a273b64ff8c4f172",
      "8f2a045af51148ff8ba3e239f9170255",
      "ad2971ecf2e04c22b77dba9284df8676",
      "f0baf1ed59504f67979e9aebac4c07a5",
      "80ad00902f4e45afb912f4da06780b3a",
      "95bfec42d56a4f4e918a6cd6c2558147",
      "3f861c8b98e0427c9b5fc82f27d8a92a",
      "8a2d650125ab4d02a2cc8e1996214d4a",
      "f86be29bbc594309bb8594a2ce1a51e2",
      "5c003239df724c37904f6f40ec2f76e1",
      "942f1049d7a94f9091bbcb57172ed14b",
      "7ae4459b47b446edb2f1841da5295852",
      "a2e4c9d885d44973a65fd6a329b07561",
      "7705c545ce7942b88dd496a106928c5f",
      "41c04fea71364ea1a83dcf120adcef32",
      "2cf6072049d04a618bb3a80e8303fcd0",
      "3541747f05de4af1af4e8550c78c27a3",
      "482802c769314236ada1b4e0b977fab3",
      "f536e3cf41a245c298ac5ca8016ffdd4",
      "c9874d1fe641468a9d7f1ec33aef2312",
      "c78fe40898f64d9b9500409a1b4ca050",
      "3409449829484047abb9b119a3cd882d",
      "bb91c37b7425458883446b4603a242ad",
      "05c4c46877d1471d891d5770bb9f86ab",
      "ea86477b7edb4e3bb3359533dc862a81",
      "90700c00eb494504bd2e3c5d61cbcd30",
      "2e2283d92e7f4d0581ecd5e76017f26d",
      "e4c31f5d7d274763b2e1702d13a9b9e2",
      "a49f1643328849a5a2742c113f468158",
      "99a9556af9ec4754bc181f2fb8bad348",
      "abe9f582de1944e59a756f83cff70a91",
      "a41bb2a129854ec4a08325b00550dbea",
      "d4fd5d800dea4012a9411f75aab3ae67",
      "00cfdca0b50f4405bb725538bd094fd9",
      "6396c72edd974a4e923d0ca0f1b9ad48",
      "d60072d604064cb0a099cd0e40069bfc",
      "b3a15eb55a474b5ba09e152e292940f0",
      "3f2bac18e56145438715201c2c911f34",
      "9c4a67a2ea504390ad9bc46342693fba",
      "868528d7f2bc474cbb19301db50dec72",
      "d11d04498dae45bf965945b7d5802ba3",
      "7ed74655b8b14bd8909f6a9d17ae6d97",
      "1459ba4f12e54673a52100d827500aa1",
      "3ab444788cb7403e9e7cf1aae6a5eb2c",
      "230197a035cd4a48a212e81f0ca9d26a",
      "1ceb4c9d2b724360a8d334bdd520787e",
      "c61ca17e518d4c1c9aa7eb13f65d2f06",
      "1e0361661de14c3daf1d611028ae8baf",
      "8dd7ddea2b58454aaea89ed870fba968",
      "b9c5c5a2d81b4b48a27782abb7e19de7",
      "28afe81bbc764296b233306931a99470",
      "8879e95802e6486889acfb0e50bace23",
      "b4bfad06af684980a5fdc569cee7c1ea",
      "e46cbfcb42cc46daac63d634a5106b0f",
      "4dfae73ee0a747ef88143bb7bf12cf2c",
      "773db3b2686a493e847203af583d58a4",
      "bac08ede3abe4e9aa0918819abfe3d0c",
      "fa24d5290f84403fb1d5554ceeb9b801",
      "1c325e79145044f8ab0f6f9b2255f1c6",
      "1b57c326de2b49c9ad2e15f2bc4bb094",
      "1069b4264eb44fc6bbc17fc77a30a2b2",
      "71e53b03a21245fe9006de8982481d56"
     ]
    },
    "id": "VLtjnSvQrd73",
    "outputId": "335be528-2146-4535-9570-3f9cdc9bbd36"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae00d74c8e7e4df4bf78a306a337ae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b66a539cf6a44e9b91b4c83727f8b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2d650125ab4d02a2cc8e1996214d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f536e3cf41a245c298ac5ca8016ffdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a9556af9ec4754bc181f2fb8bad348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11d04498dae45bf965945b7d5802ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8879e95802e6486889acfb0e50bace23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 921,600 || all params: 2,507,094,016 || trainable%: 0.0368\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2b-it\",\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    token=True\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JwrFWbITsQo9",
    "outputId": "522addd2-fc2e-40d4-fb9e-e37d7a4eb96c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3660813980.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:457: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 11:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.848200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.996200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.632900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.649800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.844500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.547600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.643300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.417200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=3.9497398885091144, metrics={'train_runtime': 684.7515, 'train_samples_per_second': 0.876, 'train_steps_per_second': 0.438, 'total_flos': 3654708048691200.0, 'train_loss': 3.9497398885091144, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gemma-finance-lora\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # No masked language modeling since we're doing causal LM\n",
    ")\n",
    "\n",
    "# Use only a smaller subset of the dataset for quicker training (e.g., 2000 samples)\n",
    "small_train_dataset = tokenized_ds.select(range(200))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5azeF27osv0t",
    "outputId": "c3cf214c-ecae-4fb4-801d-0d973c89d6dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Utilize your financial knowledge, give your answer to the input:\n",
      "\n",
      "What are the benefits of portfolio diversification?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "A sharpe ratio is a measure of the risk and reward of an investment portfolio. A sharpe ratio greater than 1 indicates that the portfolio is more likely to have higher risk, but also more likely to have higher returns. A sharpe ratio less than 1 indicates that the portfolio is more likely to have lower risk, but also more likely to have lower returns. The sharpe ratio is a useful measure of an investment portfolio's risk and reward. It can help investors to decide how to allocate their investment dollars.\n",
      "\n",
      "The benefit of portfolio diversification is that it reduces risk. When you spread your investment dollars across multiple investments, you spread the risk out. This means that if one investment falls in value, the other investments will still be worth something. This is a great way to protect your investment dollars from large losses.\n",
      "\n",
      "The benefit of portfolio diversification is also that it can help to balance your portfolio. When you spread your investment dollars across multiple investments, you create a more balanced portfolio\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "\n",
    "instruction = \"Utilize your financial knowledge, give your answer to the input:\\n\\nWhat are the benefits of portfolio diversification?\"\n",
    "prompt = f\"<start_of_turn>user\\n{instruction}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "\n",
    "response = pipe(prompt, max_new_tokens=200)[0]['generated_text']\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7wCTqZc55AW"
   },
   "source": [
    "##Analyzing annual reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFw9Zqp34qrc",
    "outputId": "345cd7c9-c4f9-4f03-c999-4d7fc3c18c39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Set up your pipeline (assuming model and tokenizer are already loaded)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "\n",
    "def analyze_financial_text(text_chunk):\n",
    "    instruction = (\n",
    "        \"You are a financial analyst. Read the following financial text and summarize key insights, risks, and opportunities:\\n\\n\"\n",
    "        f\"{text_chunk}\"\n",
    "    )\n",
    "    prompt = f\"<start_of_turn>user\\n{instruction}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    return pipe(prompt, max_new_tokens=300)[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ba0xaz6H5K2k",
    "outputId": "ebfd4f47-7813-42b7-f95c-8017b3ee7264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "You are a financial analyst. Read the following financial text and summarize key insights, risks, and opportunities:\n",
      "\n",
      "\n",
      "In fiscal year 2023, the company experienced a 12% increase in net revenue, primarily driven by the growth in cloud services and enterprise solutions.\n",
      "Operating expenses rose by 7%, largely due to increased R&D investment. International markets contributed 45% of total revenue.\n",
      "However, geopolitical tensions and rising interest rates posed challenges in key markets.\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "**Insights:**\n",
      "- Company's growth in cloud services and enterprise solutions.\n",
      "- International market contribution of 45%.\n",
      "- Geopolitical tensions and rising interest rates posed challenges in key markets.\n",
      "- Increased R&D investment.\n",
      "\n",
      "\n",
      "**Risks:**\n",
      "- Dependence on cloud services and enterprise solutions.\n",
      "- Geopolitical tension and rising interest rates in key markets.\n",
      "- Dependence on international markets.\n",
      "\n",
      "\n",
      "**Opportunities:**\n",
      "- Growing demand for cloud services and enterprise solutions.\n",
      "- Expansion into new markets.\n",
      "- Investing in R&D to stay competitive.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "In fiscal year 2023, the company experienced a 12% increase in net revenue, primarily driven by the growth in cloud services and enterprise solutions.\n",
    "Operating expenses rose by 7%, largely due to increased R&D investment. International markets contributed 45% of total revenue.\n",
    "However, geopolitical tensions and rising interest rates posed challenges in key markets.\n",
    "\"\"\"\n",
    "\n",
    "output = analyze_financial_text(sample_text)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAA_DOFn6A7k"
   },
   "source": [
    "##Evaluating a user’s current investment portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kyP77dG45NlG"
   },
   "outputs": [],
   "source": [
    "def analyze_portfolio(text_portfolio):\n",
    "    instruction = (\n",
    "        \"You are a financial advisor. Analyze the following investment portfolio and provide insights on:\\n\"\n",
    "        \"- Diversification\\n\"\n",
    "        \"- Sectoral exposure\\n\"\n",
    "        \"- Asset class risk\\n\"\n",
    "        \"- Growth potential\\n\\n\"\n",
    "        f\"Portfolio:\\n{text_portfolio}\"\n",
    "    )\n",
    "    prompt = f\"<start_of_turn>user\\n{instruction}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    return pipe(prompt, max_new_tokens=300)[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpiTxkTu6No7",
    "outputId": "2c2d68e8-8d2a-4584-993f-3f2f42489e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "You are a financial advisor. Analyze the following investment portfolio and provide insights on:\n",
      "- Diversification\n",
      "- Sectoral exposure\n",
      "- Asset class risk\n",
      "- Growth potential\n",
      "\n",
      "Portfolio:\n",
      "\n",
      "The user holds the following:\n",
      "- 40% in large-cap US tech stocks (Apple, Microsoft, Nvidia)\n",
      "- 20% in government bonds (10-year US Treasury)\n",
      "- 15% in REITs (Real Estate Investment Trusts)\n",
      "- 10% in emerging market equities\n",
      "- 10% in gold\n",
      "- 5% in a cryptocurrency ETF\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "## Insights on Investment Portfolio\n",
      "\n",
      "**Diversification:**\n",
      "The portfolio has a very high diversification among different asset classes and industries. This is a good approach to mitigate the risk of losing money in one specific sector or asset class. However, the portfolio is very concentrated in the tech sector, with a large allocation to Apple, Microsoft, and Nvidia. This could be a risk if these companies perform poorly.\n",
      "\n",
      "**Sectoral Exposure:**\n",
      "The portfolio has a significant allocation to the tech sector (40%). This could be a risk if the tech sector performs poorly.\n",
      "\n",
      "**Asset Class Risk:**\n",
      "The portfolio mainly consists of large-cap stocks and government bonds. This makes the portfolio more susceptible to corporate or economic risks.\n",
      "\n",
      "**Growth Potential:**\n",
      "The portfolio has a very low allocation to emerging market equities (10%). Emerging market equities have the potential for higher growth, but it's also a more risky investment.\n",
      "\n",
      "**Overall:**\n",
      "The portfolio seems to be well-diversified and balanced across different asset classes and industries. However, the high concentration in the tech sector is a risk. The low allocation to emerging market equities also puts the portfolio at a higher risk of default.\n",
      "\n",
      "**Additional Considerations:**\n",
      "\n",
      "* It is important to diversify your portfolio within each sector. For example, you could have a higher allocation to tech stocks in a portfolio that also holds government bonds.\n",
      "* You should also consider diversifying your portfolio across different geographies. This will help to reduce\n"
     ]
    }
   ],
   "source": [
    "user_portfolio = \"\"\"\n",
    "The user holds the following:\n",
    "- 40% in large-cap US tech stocks (Apple, Microsoft, Nvidia)\n",
    "- 20% in government bonds (10-year US Treasury)\n",
    "- 15% in REITs (Real Estate Investment Trusts)\n",
    "- 10% in emerging market equities\n",
    "- 10% in gold\n",
    "- 5% in a cryptocurrency ETF\n",
    "\"\"\"\n",
    "\n",
    "response = analyze_portfolio(user_portfolio)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32M8n0N86huR"
   },
   "source": [
    "##Generating strategic suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9MI3_v3R6PZf"
   },
   "outputs": [],
   "source": [
    "def generate_investment_suggestions(text_portfolio):\n",
    "    instruction = (\n",
    "        \"You are a financial strategist. Based on the portfolio provided below, give:\\n\"\n",
    "        \"- Rebalancing suggestions\\n\"\n",
    "        \"- Stocks or sectors to add to a watchlist\\n\"\n",
    "        \"- Flag any underperforming or overexposed sectors\\n\"\n",
    "        \"- Suggestions should reflect current financial market trends (assume up-to-date knowledge).\\n\\n\"\n",
    "        f\"Portfolio:\\n{text_portfolio}\"\n",
    "    )\n",
    "    prompt = f\"<start_of_turn>user\\n{instruction}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    return pipe(prompt, max_new_tokens=350)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ExMw-Gf36uh-",
    "outputId": "17570c94-0a32-4be8-cb72-5856ef476b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "You are a financial strategist. Based on the portfolio provided below, give:\n",
      "- Rebalancing suggestions\n",
      "- Stocks or sectors to add to a watchlist\n",
      "- Flag any underperforming or overexposed sectors\n",
      "- Suggestions should reflect current financial market trends (assume up-to-date knowledge).\n",
      "\n",
      "Portfolio:\n",
      "\n",
      "40% Apple, Microsoft, Nvidia (US Tech)\n",
      "20% US Treasury Bonds\n",
      "10% Gold\n",
      "10% India Small Cap Stocks\n",
      "10% Real Estate REITs\n",
      "10% Cash\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "**Rebalancing Suggestions:**\n",
      "- Consider adding some US stocks, like Tesla or Amazon.\n",
      "- Consider adding some international stocks, like Alibaba or Tencent.\n",
      "- Consider adding some smaller US REITs.\n",
      "\n",
      "**Stocks to add to a watchlist:**\n",
      "- TSLA\n",
      "- AAPL\n",
      "- MSFT\n",
      "- GOOGL\n",
      "- INOC\n",
      "- INTC\n",
      "- FLTR\n",
      "\n",
      "**Flag any underperforming or overexposed sectors:**\n",
      "- Consider adding some small US stocks to a watchlist.\n",
      "- Consider adding some international stocks to a watchlist.\n",
      "\n",
      "**Suggestions:**\n",
      "- Consider adding some US stocks to your portfolio.\n",
      "- Consider adding some international stocks to your portfolio.\n",
      "- Review your portfolio quarterly to adjust it based on your financial situation.\n",
      "- Consider adding some smaller US REITs to your portfolio.\n",
      "- Consider adding some international stocks to your portfolio.\n"
     ]
    }
   ],
   "source": [
    "portfolio = \"\"\"\n",
    "40% Apple, Microsoft, Nvidia (US Tech)\n",
    "20% US Treasury Bonds\n",
    "10% Gold\n",
    "10% India Small Cap Stocks\n",
    "10% Real Estate REITs\n",
    "10% Cash\n",
    "\"\"\"\n",
    "\n",
    "suggestions = generate_investment_suggestions(portfolio)\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Agbsj5_56wP0",
    "outputId": "fb56fed1-d9dc-429e-b76c-fb8eed567f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gemma-finance-lora/tokenizer_config.json',\n",
       " './gemma-finance-lora/special_tokens_map.json',\n",
       " './gemma-finance-lora/chat_template.jinja',\n",
       " './gemma-finance-lora/tokenizer.model',\n",
       " './gemma-finance-lora/added_tokens.json',\n",
       " './gemma-finance-lora/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./gemma-finance-lora\")\n",
    "tokenizer.save_pretrained(\"./gemma-finance-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkvZ1QqWw6f3",
    "outputId": "f84943ed-32f5-4302-8173-b5cc2fb056af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
      "Successfully installed pydeck-0.9.1 streamlit-1.47.1 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CaJWqmYyw-k-",
    "outputId": "8b19fe80-dfba-4235-edd3-c0bdf456be0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "st.set_page_config(page_title=\"Finance Assistant\", layout=\"wide\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./gemma-finance-lora\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"./gemma-finance-lora\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = load_model()\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(output[0])  # Don’t skip special tokens\n",
    "\n",
    "def extract_model_answer(response):\n",
    "    try:\n",
    "        if \"<start_of_turn>model\" in response and \"<end_of_turn>\" in response:\n",
    "            answer = response.split(\"<start_of_turn>model\")[1].split(\"<end_of_turn>\")[0].strip()\n",
    "            return answer\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"📊 Financial LLM Assistant\")\n",
    "\n",
    "mode = st.sidebar.radio(\"Select Task\", [\"Q&A\", \"Analyze Annual Report\", \"Evaluate Portfolio\", \"Get Suggestions\"])\n",
    "\n",
    "def handle_response(prompt_text):\n",
    "    st.info(\"Generating response...\")\n",
    "    response = generate_response(prompt_text)\n",
    "    answer = extract_model_answer(response)\n",
    "    if answer:\n",
    "        st.markdown(\"**Answer:**\")\n",
    "        st.write(answer)\n",
    "    else:\n",
    "        st.warning(\"⚠️ Model response not in expected format. Displaying raw output:\")\n",
    "        st.code(response)\n",
    "\n",
    "if mode == \"Q&A\":\n",
    "    user_query = st.text_area(\"💬 Enter your financial question:\")\n",
    "    if st.button(\"Submit\"):\n",
    "        if user_query.strip():\n",
    "            prompt = f\"<start_of_turn>user\\n{user_query}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "            handle_response(prompt)\n",
    "\n",
    "elif mode == \"Analyze Annual Report\":\n",
    "    report = st.text_area(\"📄 Paste a section of an annual report:\")\n",
    "    if st.button(\"Analyze\"):\n",
    "        if report.strip():\n",
    "            prompt = f\"<start_of_turn>user\\nSummarize this section from an annual report:\\n{report}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "            handle_response(prompt)\n",
    "\n",
    "elif mode == \"Evaluate Portfolio\":\n",
    "    portfolio = st.text_area(\"📈 Paste your investment portfolio (e.g., tickers, sectors, weights):\")\n",
    "    if st.button(\"Evaluate\"):\n",
    "        if portfolio.strip():\n",
    "            prompt = f\"<start_of_turn>user\\nEvaluate this portfolio:\\n{portfolio}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "            handle_response(prompt)\n",
    "\n",
    "elif mode == \"Get Suggestions\":\n",
    "    portfolio = st.text_area(\"🧠 Paste your portfolio to get improvement suggestions:\")\n",
    "    if st.button(\"Suggest\"):\n",
    "        if portfolio.strip():\n",
    "            prompt = f\"<start_of_turn>user\\nGive strategic suggestions for this portfolio including rebalancing, underperformers, and watchlist ideas:\\n{portfolio}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "            handle_response(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ek5lmnmDxwet",
    "outputId": "223393c8-e88f-4b7c-b9bf-75a04416a736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok\n",
    "!ngrok config add-authtoken 30jXw8LZ4E9XoWOx3YI7vjD3vne_32ik6279ZmxsQxjBpsJEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_FxA-llA9sQ",
    "outputId": "d996c723-13ed-45cc-9d2d-d89dbff2cabe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open your app at: NgrokTunnel: \"https://3d7344867593.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.231.226.208:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2025-08-02 14:09:17.074171: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754143757.196892   17713 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754143757.242275   17713 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Loading checkpoint shards: 100% 2/2 [00:28<00:00, 14.29s/it]\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "public_url = ngrok.connect(8501)\n",
    "print(\"Open your app at:\", public_url)\n",
    "\n",
    "!streamlit run app.py &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LijjB1bVBxtp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
